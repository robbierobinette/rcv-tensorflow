{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbie/work/rcv-tensorflow/ActionMemory.py:49: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (self.depth == state.shape[1], \"depth must match\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from Tensor import Tensor\n",
    "from ActionMemory import ActionMemory\n",
    "\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "from Ballot import Ballot\n",
    "from DefaultConfigOptions import *\n",
    "from ElectionConstructor import ElectionConstructor, construct_irv, construct_h2h\n",
    "from ModelStats import ModelStats\n",
    "from NDPopulation import NDPopulation\n",
    "from ProcessResult import ProcessResult\n",
    "from Timings import Timings\n",
    "from PluralityElection import PluralityElection\n",
    "import datetime as datetime\n",
    "\n",
    "# Parameters for Ornsteinâ€“Uhlenbeck process\n",
    "THETA = 0.15\n",
    "DT = 1e-1\n",
    "\n",
    "class CandidateActor(tf.keras.Model):\n",
    "    def __init__(self, ideology_dim: int, n_latent: int, width: int):\n",
    "        super().__init__()\n",
    "        self.ideology_dim = ideology_dim\n",
    "        self.n_latent = n_latent\n",
    "\n",
    "        self.encoding_layers = []\n",
    "        self.encoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"actor-enc1\"))\n",
    "        self.encoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"actor-enc2\"))\n",
    "        self.encoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"actor-enc3\"))\n",
    "\n",
    "        self.state = tf.keras.layers.Dense(self.n_latent)\n",
    "\n",
    "        self.decoding_layers = []\n",
    "        self.decoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"actor-dec1\"))\n",
    "        self.decoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"actor-dec2\"))\n",
    "        self.decoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"actor-dec3\"))\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(.3, name=\"actor-dropout\")\n",
    "        self.returns = tf.keras.layers.Dense(ideology_dim, name=\"actor-returns\")\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    # input is a tensor of shape (batch_size, n_observations (n_candidates), input_dim)\n",
    "    def call(self, state: Tensor, training: bool = None, mask: bool = None) -> Tensor:\n",
    "        # runs the encoder portion of the model on a single input\n",
    "        # print(f\"Actor.call, {state.dtype=}\")\n",
    "        if state.shape[1] != 0:\n",
    "            x = state\n",
    "            for e in self.encoding_layers:\n",
    "                x = self.dropout(e(x), training=training)\n",
    "            # reduce to state observations\n",
    "            encoded_observations = self.dropout(self.state(x), training=training)\n",
    "            # now, sum the observations (which have been put on dim 1)\n",
    "            encoded_state = tf.reduce_sum(encoded_observations, axis=1, keepdims=False)\n",
    "        else:\n",
    "            # this corresponds to no candidates in the race yet.\n",
    "            batch_size = state.shape[0]\n",
    "            encoded_state = tf.zeros(shape=(batch_size, self.n_latent), dtype=tf.dtypes.float32)\n",
    "\n",
    "        # use that composite state to predict the returns for each possible action\n",
    "        x = encoded_state\n",
    "        for d in self.decoding_layers:\n",
    "            x = self.dropout(d(x), training=training)\n",
    "\n",
    "        result = self.returns(x)\n",
    "        # print(f\"Actor.call:  {result.dtype=} \")\n",
    "        return result\n",
    "\n",
    "class CandidateCritic(tf.keras.Model):\n",
    "    def __init__(self, ideology_dim: int, n_latent: int, width: int):\n",
    "        super().__init__()\n",
    "        self.ideology_dim = ideology_dim\n",
    "        self.n_latent = n_latent\n",
    "\n",
    "        self.encoding_layers = []\n",
    "        self.encoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"critc-enc1\"))\n",
    "        self.encoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"critc-enc2\"))\n",
    "        self.encoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"critc-enc3\"))\n",
    "\n",
    "        self.state = tf.keras.layers.Dense(self.n_latent)\n",
    "\n",
    "        self.decoding_layers = []\n",
    "        self.decoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"critic-dec1\"))\n",
    "        self.decoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"critic-dec2\"))\n",
    "        self.decoding_layers.append(tf.keras.layers.Dense(width, activation='relu', name=\"critic-dec3\"))\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(.3)\n",
    "        self.returns = tf.keras.layers.Dense(ideology_dim, name=\"critic-returns\")\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    # input is a tensor of shape (batch_size, n_observations (n_candidates), input_dim)\n",
    "    def call(self, state: Tensor, action: Tensor, training: bool = None, mask: bool = None) -> Tensor:\n",
    "        # runs the encoder portion of the model on a single input\n",
    "        # print(\"Critic.call:\")\n",
    "        # print(f\"\\t{state.shape=} \")\n",
    "        # print(f\"\\t{state.dtype=} \")\n",
    "        # print(f\"\\t{action.shape=} \")\n",
    "        # print(f\"\\t{action.dtype=}\")\n",
    "        if state.shape[1] != 0:\n",
    "            x = state\n",
    "            for e in self.encoding_layers:\n",
    "                x = self.dropout(e(x), training=training)\n",
    "            # reduce to state observations\n",
    "            encoded_observations = self.dropout(self.state(x), training=training)\n",
    "            # now, sum the observations (which have been put on dim 1)\n",
    "            encoded_state = tf.reduce_sum(encoded_observations, axis=1, keepdims=False)\n",
    "        else:\n",
    "            # this corresponds to no candidates in the race yet.\n",
    "            batch_size = state.shape[0]\n",
    "            encoded_state = tf.zeros(shape=(batch_size, self.n_latent), dtype=tf.dtypes.float32)\n",
    "\n",
    "        # use the composite state and action to predict the returns for the given action\n",
    "        # print(f\"critic.call:  {encoded_state.shape=} {encoded_state.dtype=} {action.shape=} {action.dtype=}\")\n",
    "        x = tf.concat([encoded_state, action], axis = 1)\n",
    "        for d in self.decoding_layers:\n",
    "            x = self.dropout(d(x), training=training)\n",
    "\n",
    "        return self.returns(x)\n",
    "\n",
    "class CandidateAgent:\n",
    "    def __init__(self, ideology_dim: int, n_latent: int, width: int, learn_rate: float):\n",
    "        self.ideology_dim = ideology_dim\n",
    "        self.n_latent = n_latent\n",
    "        self.width = width\n",
    "        self.learn_rate = .001\n",
    "        self.gamma = .99\n",
    "        self.tau = .01\n",
    "\n",
    "        self.actor = CandidateActor(ideology_dim, n_latent, width)\n",
    "        self.target_actor = CandidateActor(ideology_dim, n_latent, width)\n",
    "\n",
    "        self.critic = CandidateCritic(ideology_dim, n_latent, width)\n",
    "        self.target_critic = CandidateCritic(ideology_dim, n_latent, width)\n",
    "        self.memory = ActionMemory(1024, ideology_dim, ideology_dim)\n",
    "\n",
    "        self.lower_bound = -2\n",
    "        self.upper_bound = 2\n",
    "        self.global_step = 0\n",
    "\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.log_dir = 'logs/' + current_time + '/train'\n",
    "        self.summary_writer = tf.summary.create_file_writer(self.log_dir)\n",
    "\n",
    "    def train(self, batch_size: int):\n",
    "        for depth in self.memory.depths():\n",
    "            state, action, reward = self.memory.get_batch(depth, batch_size)\n",
    "            self.update(state, action, reward, state, True)\n",
    "        self.global_step += 1\n",
    "\n",
    "    def update(self, state, action, reward, new_state, done):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.target_actor(new_state)\n",
    "            target_critic_values = self.target_critic(new_state, target_actions)\n",
    "            critic_value = self.critic.call(state, action)\n",
    "            target = reward + self.gamma * target_critic_values * (1-done)\n",
    "            critic_loss = tf.keras.losses.MSE(target, critic_value)\n",
    "\n",
    "        critic_gradient = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        gv = [(g, v) for g, v in zip(critic_gradient, self.critic.trainable_variables) if g is not None]\n",
    "        self.critic.optimizer.apply_gradients(gv)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            policy_actions = self.actor(state)\n",
    "            actor_loss = -self.critic(state, policy_actions)\n",
    "            actor_loss = tf.math.reduce_mean(actor_loss)\n",
    "\n",
    "        actor_gradient = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        gv = [(g, v) for g, v in zip(actor_gradient, self.actor.trainable_variables) if g is not None]\n",
    "        self.actor.optimizer.apply_gradients(gv)\n",
    "\n",
    "        self.update_target_networks(self.tau)\n",
    "\n",
    "    def _ornstein_uhlenbeck_process(self, x, theta=THETA, mu=0, dt=DT, std=0.2):\n",
    "        \"\"\"\n",
    "        Ornsteinâ€“Uhlenbeck process\n",
    "        \"\"\"\n",
    "        return x + theta * (mu-x) * dt + std * np.sqrt(dt) * np.random.normal(size=self.ideology_dim)\n",
    "\n",
    "    def get_action(self, observation, noise, evaluation=False):\n",
    "        state = tf.convert_to_tensor([observation], dtype=tf.float32)\n",
    "        actions = self.actor(state)\n",
    "        if not evaluation:\n",
    "            self.noise = self._ornstein_uhlenbeck_process(noise)\n",
    "            actions += self.noise\n",
    "\n",
    "        actions = tf.clip_by_value(actions, self.lower_bound, self.upper_bound)\n",
    "\n",
    "        return actions[0]\n",
    "\n",
    "    def update_target_networks(self, tau):\n",
    "        actor_weights = self.actor.weights\n",
    "        target_actor_weights = self.target_actor.weights\n",
    "        for index in range(len(actor_weights)):\n",
    "            target_actor_weights[index] = tau * actor_weights[index] + (1 - tau) * target_actor_weights[index]\n",
    "\n",
    "        self.target_actor.set_weights(target_actor_weights)\n",
    "\n",
    "        critic_weights = self.critic.weights\n",
    "        target_critic_weights = self.target_critic.weights\n",
    "\n",
    "        for index in range(len(critic_weights)):\n",
    "            target_critic_weights[index] = tau * critic_weights[index] + (1 - tau) * target_critic_weights[index]\n",
    "\n",
    "        self.target_critic.set_weights(target_critic_weights)\n",
    "\n",
    "    def ready(self) -> bool:\n",
    "        return self.memory.ready()\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_ideology_to_input(ideology: Ideology) -> Tensor:\n",
    "        return ideology.vec.astype(dtype=np.float32)\n",
    "\n",
    "    def choose_ideology(self, opponents: List[Candidate]):\n",
    "        state = self.get_state_from_opponents(opponents)\n",
    "        ideology_pred = self.actor.call(state, training=True)\n",
    "        ideology_pred = tf.reshape(ideology_pred, shape=(self.ideology_dim,))\n",
    "        return ideology_pred.numpy()\n",
    "\n",
    "    def get_state_from_opponents(self, opponents: List[Candidate]) -> Tensor:\n",
    "        # shape is (observation_id, ideology_representation_vec)\n",
    "        if len(opponents) != 0:\n",
    "            candidate_observations = [self.convert_ideology_to_input(o.ideology) for o in opponents]\n",
    "            # print(\"candidate_observations\")\n",
    "            # for o in candidate_observations:\n",
    "            #     print(f\"\\t{o.shape=}\")\n",
    "            state = np.stack(candidate_observations)\n",
    "        else:\n",
    "            state = tf.zeros(shape=(0, self.ideology_dim), dtype=tf.dtypes.float32)\n",
    "\n",
    "        return tf.expand_dims(state, 0)\n",
    "\n",
    "    def add_sample_from_candidates(self, candidate: Candidate, opponents: List[Candidate], winner: Candidate):\n",
    "        state = self.get_state_from_opponents(opponents)\n",
    "\n",
    "        action = self.convert_ideology_to_input(candidate.ideology)\n",
    "        action = tf.expand_dims(action, 0)\n",
    "\n",
    "        if winner == candidate:\n",
    "            reward = tf.ones(shape=(1, 1), dtype=tf.dtypes.float32)\n",
    "        else:\n",
    "            reward = tf.zeros(shape=(1, 1), dtype=tf.dtypes.float32)\n",
    "\n",
    "        self.memory.add_sample(state, action, reward)\n",
    "\n",
    "    def save_to_file(self, path: str):\n",
    "        self.actor.save( path + \".actor\")\n",
    "        self.critic.save( path + \".critic\")\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        state = self.__dict__.copy()\n",
    "        # Don't pickle the model\n",
    "        del state[\"actor\"]\n",
    "        del state[\"critic\"]\n",
    "        del state[\"memory\"]\n",
    "        del state[\"optimizer\"]\n",
    "        del state[\"summary_writer\"]\n",
    "        return state\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_model_and_population(ideology_dim: int) -> (CandidateAgent, NDPopulation):\n",
    "    ideology_bins = 64\n",
    "    hidden_ratio = 4\n",
    "    n_hidden = hidden_ratio * ideology_bins * ideology_dim\n",
    "    n_latent = ideology_bins * ideology_dim\n",
    "    batch_size = 128\n",
    "    learn_rate = .001\n",
    "\n",
    "    model = CandidateAgent( ideology_dim=ideology_dim,\n",
    "                                     n_latent = n_latent,\n",
    "                                     width=n_hidden,\n",
    "                                     learn_rate= learn_rate)\n",
    "\n",
    "    population_means = np.zeros(shape=(ideology_dim,))\n",
    "    population_stddev = np.ones(shape=(ideology_dim,))\n",
    "    pop = NDPopulation(population_means, population_stddev)\n",
    "    return model, pop\n",
    "\n",
    "def measure_representation(candidate: Candidate, voters: List[Voter]) -> float:\n",
    "    n_voters = len(voters)\n",
    "    balance = []\n",
    "    for d in range(candidate.ideology.dim):\n",
    "        lc = len([v for v in voters if v.ideology.vec[d] < candidate.ideology.vec[d]])\n",
    "        balance.append(min(lc / n_voters, 1 - lc / n_voters))\n",
    "    return float(np.mean(balance))\n",
    "\n",
    "def gen_non_model_candidates(model: CandidateAgent, population: NDPopulation) -> List[Candidate]:\n",
    "    candidates: List[Candidate] = []\n",
    "    if model.ready():\n",
    "        if np.random.choice([True, False]):\n",
    "            candidates += gen_pilot_candidates(population, .8)\n",
    "        else:\n",
    "            candidates += gen_random_candidates(population, 3)\n",
    "    else:\n",
    "        candidates += gen_pilot_candidates(population, .6)\n",
    "        candidates += gen_random_candidates(population, 3)\n",
    "\n",
    "    np.random.shuffle(candidates)\n",
    "    return candidates\n",
    "\n",
    "def gen_pilot_candidates(population: NDPopulation, spacing: float) -> List[Candidate]:\n",
    "    candidates = []\n",
    "    dim = population.dim\n",
    "    d = spacing\n",
    "    fuzz = .05\n",
    "    c1_vec = np.random.normal(0, .01, dim)\n",
    "    c1_vec[0] += np.random.normal(d, fuzz)\n",
    "    candidates.append( Candidate(\"P-R\", Independents, ideology=Ideology(c1_vec), quality=0))\n",
    "\n",
    "    c2_vec = np.random.normal(0, .01, dim)\n",
    "    c2_vec[0] -= np.random.normal(d, fuzz)\n",
    "    candidates.append(Candidate(\"P-L\", Independents, ideology=Ideology(c2_vec), quality=0))\n",
    "\n",
    "    c3_vec = np.random.normal(0, .02, dim)\n",
    "    candidates.append(Candidate(\"P-C\", Independents, ideology=Ideology(c3_vec), quality=0))\n",
    "\n",
    "    return candidates\n",
    "\n",
    "def gen_random_candidates(population: NDPopulation, n: int)-> List[Candidate]:\n",
    "    candidates = []\n",
    "    for i in range(3):\n",
    "        ivec = population.unit_sample_voter().ideology.vec * .5\n",
    "        candidates.append(Candidate(\"r-\" + str(i), Independents, Ideology(ivec), 0))\n",
    "\n",
    "    return candidates\n",
    "\n",
    "def run_sample_election(model: CandidateAgent, process: ElectionConstructor, population: NDPopulation, train: bool):\n",
    "    candidates = []\n",
    "    model_entries = set(np.random.choice(range(6), 3, replace=False))\n",
    "    r_candidates = gen_non_model_candidates(model, population)\n",
    "    for i in range(6):\n",
    "        if i in model_entries and model.ready():\n",
    "            ideology = Ideology(model.choose_ideology(candidates))\n",
    "            c = Candidate(\"m-\" + str(i), Independents, ideology, 0)\n",
    "        else:\n",
    "            if train:\n",
    "                c = r_candidates.pop()\n",
    "            else:\n",
    "                ideology = population.unit_sample_voter().ideology\n",
    "                c = Candidate(\"r-\" + str(i), Independents, ideology, 0)\n",
    "\n",
    "        candidates += [c]\n",
    "\n",
    "    voters = population.generate_unit_voters(1000)\n",
    "    ballots = [Ballot(v, candidates, unit_election_config) for v in voters]\n",
    "    result = process.run(ballots, set(candidates))\n",
    "    winner = result.winner()\n",
    "    balance = measure_representation(winner, voters)\n",
    "\n",
    "    return winner, candidates, balance\n",
    "\n",
    "def train_candidate_model(model: CandidateAgent, process: ElectionConstructor, population: NDPopulation, max_steps=5000):\n",
    "    timings = Timings()\n",
    "    stats = ModelStats()\n",
    "    first = True\n",
    "    while model.global_step < max_steps:\n",
    "        winner, candidates, balance = run_sample_election(model, process, population, True)\n",
    "        for i in range(len(candidates)):\n",
    "            model.add_sample_from_candidates(candidates[i], candidates[0:i], winner)\n",
    "\n",
    "        if model.ready():\n",
    "            if first:\n",
    "                print(\"starting to train\")\n",
    "                first = False\n",
    "\n",
    "            stats.update(winner, candidates, balance)\n",
    "            with timings.time_block(\"model.train\"):\n",
    "                model.train(128)\n",
    "            s = model.global_step\n",
    "            if (s < 100 and s % 10 == 0) or (s < 1000 and s % 100 == 0) or s % 1000 == 0:\n",
    "                stats.print(process.name, model.global_step)\n",
    "                stats.reset()\n",
    "\n",
    "    timings.print()\n",
    "\n",
    "\n",
    "def check_stats(stats: ModelStats, model: CandidateAgent, process: ElectionConstructor, population: NDPopulation):\n",
    "    results=[]\n",
    "    timings = Timings()\n",
    "    for i in range(1000):\n",
    "        winner, candidates, balance = run_sample_election(model, process, population, train=False)\n",
    "        stats.update(winner, candidates, balance)\n",
    "\n",
    "\n",
    "def run_parameter_set(process: ElectionConstructor, ibins: int, dim: int):\n",
    "    save_path = \"models/cm-%s-%03d-%dD.p\" % (process.name, ibins, dim)\n",
    "    model, population = create_model_and_population(dim)\n",
    "    if os.path.exists(save_path):\n",
    "        with open(save_path, \"rb\") as f:\n",
    "            model: CandidateAgent = pickle.load(f)\n",
    "    else:\n",
    "        train_candidate_model(model, process, population)\n",
    "        # Saving the model file is not working at this time.\n",
    "        model.save_to_file(save_path)\n",
    "\n",
    "    stats = ModelStats()\n",
    "    check_stats(stats, model, process, population)\n",
    "    return stats, model\n",
    "\n",
    "\n",
    "def train_models():\n",
    "    dims = [1]\n",
    "    processes = [\n",
    "        ElectionConstructor(constructor=construct_irv, name=\"Instant Runoff\"),\n",
    "        ElectionConstructor(constructor=construct_h2h, name=\"Head-to-Head\"),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for bins in [64, 128]:\n",
    "        for process in processes:\n",
    "            for dim in dims:\n",
    "                stats, model = run_parameter_set(process, bins, dim)\n",
    "                results.append(ProcessResult(process, bins, dim, stats))\n",
    "                results[-1].print()\n",
    "\n",
    "    for r in results:\n",
    "        r.print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to train\n",
      " Instant Runoff     10,    10 random     33/     2  6.06% O:  0.12 model     27/     8 29.63% O: 21790.41 chance of model_winner = 80.00%\n",
      " Instant Runoff     20,    10 random     30/     0  0.00% O:  0.00 model     30/    10 33.33% O: 15666.81 chance of model_winner = 100.00%\n",
      " Instant Runoff     30,    10 random     30/     7 23.33% O:  0.52 model     30/     3 10.00% O:  3.04 chance of model_winner = 30.00%\n",
      " Instant Runoff     40,    10 random     30/     9 30.00% O:  0.38 model     30/     1  3.33% O:  0.63 chance of model_winner = 10.00%\n",
      " Instant Runoff     50,    10 random     30/     8 26.67% O:  0.44 model     30/     2  6.67% O:  0.65 chance of model_winner = 20.00%\n",
      " Instant Runoff     60,    10 random     30/     5 16.67% O:  0.47 model     30/     5 16.67% O: 12.40 chance of model_winner = 50.00%\n",
      " Instant Runoff     70,    10 random     30/     5 16.67% O:  0.22 model     30/     5 16.67% O: 11.69 chance of model_winner = 50.00%\n",
      " Instant Runoff     80,    10 random     30/     0  0.00% O:  0.00 model     30/    10 33.33% O: 368.87 chance of model_winner = 100.00%\n",
      " Instant Runoff     90,    10 random     30/     0  0.00% O:  0.00 model     30/    10 33.33% O: 99551907056.03 chance of model_winner = 100.00%\n",
      " Instant Runoff    100,    10 random     30/     7 23.33% O:  0.25 model     30/     3 10.00% O:   nan chance of model_winner = 30.00%\n",
      " Instant Runoff    200,   100 random    300/    49 16.33% O:  0.41 model    300/    51 17.00% O:   nan chance of model_winner = 51.00%\n",
      " Instant Runoff    300,   100 random    300/    53 17.67% O:  0.47 model    300/    47 15.67% O:   nan chance of model_winner = 47.00%\n",
      " Instant Runoff    400,   100 random    300/    54 18.00% O:  0.40 model    300/    46 15.33% O:   nan chance of model_winner = 46.00%\n",
      " Instant Runoff    500,   100 random    300/    51 17.00% O:  0.46 model    300/    49 16.33% O:   nan chance of model_winner = 49.00%\n",
      " Instant Runoff    600,   100 random    300/    54 18.00% O:  0.40 model    300/    46 15.33% O:   nan chance of model_winner = 46.00%\n",
      " Instant Runoff    700,   100 random    300/    45 15.00% O:  0.43 model    300/    55 18.33% O:   nan chance of model_winner = 55.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-a0a99879c9c7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mtrain_candidate_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprocess\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpopulation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m10000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0msave_test\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-6-a0a99879c9c7>\u001B[0m in \u001B[0;36msave_test\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpopulation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_model_and_population\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mideology_dim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mtrain_candidate_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprocess\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpopulation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m10000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0msave_test\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-4-053c6150896a>\u001B[0m in \u001B[0;36mtrain_candidate_model\u001B[0;34m(model, process, population, max_steps)\u001B[0m\n\u001B[1;32m    104\u001B[0m                 \u001B[0mfirst\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 106\u001B[0;31m             \u001B[0mstats\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwinner\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcandidates\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbalance\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    107\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtimings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime_block\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"model.train\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m                 \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/work/rcv-tensorflow/ModelStats.py\u001B[0m in \u001B[0;36mupdate\u001B[0;34m(self, winner, candidates, balance)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mwinner\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'm'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_model_winner\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwinner\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_random_winner\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwinner\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/work/rcv-tensorflow/ModelStats.py\u001B[0m in \u001B[0;36mupdate\u001B[0;34m(self, winner, candidates, balance)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mwinner\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'm'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_model_winner\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwinner\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_random_winner\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwinner\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1139\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1140\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1141\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1143\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1154\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1155\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1156\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1157\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1158\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def save_test():\n",
    "    m = CandidateAgent(ideology_dim=1, n_latent=32, width=128, learn_rate=.001)\n",
    "    process = ElectionConstructor(constructor=construct_irv, name=\"Instant Runoff\")\n",
    "    model, population = create_model_and_population(ideology_dim=1)\n",
    "\n",
    "    train_candidate_model(model, process, population, 10000)\n",
    "save_test()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train_models()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}